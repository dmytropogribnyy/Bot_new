import json
import os
from datetime import datetime, timedelta
from threading import Lock

from core.strategy import fetch_data_multiframe  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π, –µ—Å–ª–∏ –µ—â—ë –Ω–µ—Ç
from utils_core import extract_symbol
from utils_logging import log

CACHE_FILE = "data/cached_missed.json"  # –ë—ã–ª–æ —Ä–∞–Ω—å—à–µ –≤ constants
CACHE_LOCK = Lock()
MAX_ENTRIES = 1000


def add_missed_opportunity(symbol: str):
    symbol = extract_symbol(symbol)
    df = fetch_data_multiframe(symbol)  # üîÑ –∑–∞–º–µ–Ω–∏–ª–∏ –∑–¥–µ—Å—å
    if df is None or len(df) < 20:
        return

    price_24h_ago = df["close"].iloc[0]
    price_now = df["close"].iloc[-1]
    potential_profit = ((price_now - price_24h_ago) / price_24h_ago) * 100

    if abs(potential_profit) < 5:
        return

    atr_vol = df["atr"].iloc[-1]  # ‚úÖ —Ç–µ–ø–µ—Ä—å –Ω–∞–ø—Ä—è–º—É—é –∏–∑ df["atr"]
    avg_volume = df["volume"].iloc[-96:].mean() if len(df) >= 96 else df["volume"].mean()
    now = datetime.utcnow().isoformat()

    entry = {
        "symbol": symbol,
        "timestamp": now,
        "profit": round(potential_profit, 2),
        "atr_vol": round(atr_vol, 4),
        "avg_volume": round(avg_volume),
    }

    with CACHE_LOCK:
        cache = []
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, "r") as f:
                cache = json.load(f)

        cache.append(entry)
        cache = cache[-MAX_ENTRIES:]

        with open(CACHE_FILE, "w") as f:
            json.dump(cache, f, indent=2)


def flush_best_missed_opportunities(top_n=5):
    with CACHE_LOCK:
        if not os.path.exists(CACHE_FILE):
            return

        with open(CACHE_FILE, "r") as f:
            cache = json.load(f)

        now = datetime.utcnow()
        threshold_time = now - timedelta(minutes=30)

        recent = [e for e in cache if datetime.fromisoformat(e["timestamp"]) > threshold_time]
        if not recent:
            return

        top = sorted(recent, key=lambda x: abs(x["profit"]), reverse=True)[:top_n]

        lines = [f"- {e['symbol']} ({e['profit']}% profit, ATR vol: {e['atr_vol']}, Avg volume: {e['avg_volume']:,})" for e in top]
        log("[Top Missed Opportunities ‚Äî Last 30 min]\n" + "\n".join(lines), level="INFO")

        with open(CACHE_FILE, "w") as f:
            json.dump([], f)
